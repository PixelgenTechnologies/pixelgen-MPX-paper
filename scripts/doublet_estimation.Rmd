---
title: "Doublet estimation analysis"
author: "Max Jonatan Karlsson"
date: "2023-06-29"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Setup

## Set directory

```{r}

knitr::opts_knit$set(root.dir = "C:/Users/Max/Documents/Pixelgen/Projects/2023-technical-manuscript/")

```


## Load packages 

```{r message=FALSE, warning=FALSE, include=TRUE}

# Framework packages
library(tidyverse)
library(Seurat)

# Visualization packages
library(patchwork)
library(viridis)
library(ggforce)
library(pheatmap)
library(plotly)
library(igraph)
library(tidygraph)
library(ggraph)
library(graphlayouts)
library(ggplotify)

# Statistics packages
library(ggpubr)
library(rstatix)
library(broom)

# Utility packages
library(pbapply)

source("scripts/utility.R")
source("scripts/theme.R")

```


## Manage data

First, we convert the .pxl AnnData files to Seurat format, so we can use the standard Seurat functions for data analysis.  

### Convert pxl Anndata files

```{r}
# The folders the data is located in:
data_folders <- 
  c("C:/Users/Max/data/pixelgen/PGseq121/0.12.0/analysis/")


# Create data frame containing data file information
data_files <-
  data_folders %>% 
  list.files(full.names = T,
             recursive = T) %>% 
  enframe("i", "filename") %>% 
  filter(str_detect(filename, "dataset.pxl$"))  %>% 
  mutate(dataset = str_extract(filename, "PGseq\\d{1,3}"),
         full_id = str_remove(filename, ".*\\/") %>% 
           str_remove("\\..*"),
         sample =  str_extract(full_id, "_S\\d_") %>% 
           str_remove_all("_"),
         rds_file = paste0(filename, ".rds")) %>% 
  filter(sample %in% paste0("S", 3:4))


# Save file meta data

data_files %>% 
  write_csv("results/doublet/data files.csv")

# Convert each .pxl AnnData file to Seurat and save an .rds file 
# that is easily loaded in R
for(i in 1:nrow(data_files)) {
  
  filename = data_files$filename[i]
  newfilename = data_files$rds_file[i]
  message(paste("Converting:", filename))
  
  if(file.exists(newfilename)) {
    message("Converted file already exists\n")
    next
  }
  
  convert_pixelgenh5_seuratrds(filename, newfilename)
}
```

### Define meta data

Create a data frame containing meta data. 

```{r}

# Create a meta data table from the data file information
meta_data <-
  data_files %>% 
  select(sample, dataset, full_id) %>% 
  mutate(portion_jurkat = str_extract(full_id, "Jurkat..") %>% 
           str_remove("Jurkat") %>% 
           as.numeric() %>% 
           ifelse(is.na(.),
                  100, .),
         portion_daudi = 100 - portion_jurkat)

# Save meta data
meta_data %>% 
  write_csv("results/doublet/doublet meta data.csv")


```


### AnnData file

The AnnData file is stored in the .dataset.pxl file, and we previously converted it to a Seurat object and saved it as .rds to make it easy to retrieve. 

```{r message=FALSE, warning=FALSE}
# AnnData
pg_data <- 
  data_files %>% 
  select(sample, rds_file) %>% 
  deframe() %>% 
  lapply(readRDS)
```

We extract the component meta data and put it in a separate data frame for easy access. 

```{r message=FALSE, warning=FALSE}
# Metrics
metrics_data <- 
  pg_data %>% 
  map(. %>% 
        {.@meta.data} %>% 
        as_tibble(rownames = "component")) %>% 
  bind_rows(.id = "sample")
```

### Edge list

The edge list contains the whole Molecular Pixelation graph, where each row corresponds to a unique read, and an edge in the bipartite graph. It has been used for previous stages such as multiplet recovery, polarization, and colocalization score calculations. 

```{r message=FALSE, warning=FALSE}
# Edgelists
edgelists <-
  data_files %>%
  with(set_names(filename, sample)) %>%
  pblapply(read_edgelist) %>% 
  map(. %>% 
        select(-sequence, -count, -umi_unique_count, -upi_unique_count))
```

### Polarization and colocalization scores

The polarization and colocalization score files are tables of statistics calculated to estimate the spatial properties of markers in each individual component. 
The polarization score consists of Moran's I, which estimates the degree of non-random spatial distribution, where high score indicates more spatial structure. 
The colocalization scores consist of Jaccard index, and Pearson correlation, both calculated between pairs of markers, and across local neighborhoods of adjacent A pixels in each component. High score indicates colocalization of the two markers, while low score indicates that they do not have a spatial relationship.

```{r message=FALSE, warning=FALSE}
# Polarization & colocalization scores
loc_scores <-
  data_files %>%
  with(set_names(filename, sample)) %>%
  pblapply(read_pixeldata_item, items = c("colocalization", "polarization"))

```

## Analysis settings

```{r}

# Define some of the most important qc metrics for evaluating components
metrics_of_interest <- 
  c("edges", "umi_per_upia", "mean_reads")

# Define some filters for refining cell calling
component_filters <- 
  list(minimum_edges = 4000, 
       minimum_edge_rank = 11)


```

# Quality Control

Here we perform a quality control of the called cells, i.e. the components that have been labeled as real cells. This entails a manual refinement of the cell calling based on measured cell size by number of edges (number of unique detected antibodies), as well as removal of technical outliers. 

## Edge rank plot

The edge rank plot is used to call cells in a previous cell calling step in Pixelator. Here, we inspect it again and apply additional filters to remove cells that deviate from the component size distribution.

In this plot, the used cutoffs are marked as dashed lines, and components that are deviating more than two standard deviations from the mean (number of edges) are marked in gray. 

```{r}
plot_data <- 
  metrics_data %>% 
  group_by(sample) %>% 
  mutate(rank = rank(-edges, ties.method = "random"), 
         mean_edges = mean(log10(edges)),
         sd_edges = sd(log10(edges)),
         edges_deviation = (log10(edges) - mean_edges) / sd_edges) %>% 
  left_join(meta_data,
            by = "sample") %>% 
  ungroup()

plot_data %>% 
  ggplot(aes(rank, edges, color = sample)) +
  geom_point(size = 0.5) +
  geom_hline(yintercept = component_filters$minimum_edges,
             linetype = "dashed") +
  geom_vline(xintercept = component_filters$minimum_edge_rank,
             linetype = "dashed") +
  # scale_y_log10() +
  scale_x_log10(breaks = c(1, 10, 100, 500)) +
  labs(x = "Component rank (by number of edges)",
       y = "Number of edges") +
  theme_pg() 

ggsave("results/doublet/edge rank plot.png",
       width = 7, height = 5)
ggsave("results/doublet/edge rank plot.png",
       width = 7, height = 5)
```



Here we make a table saving the information of which cells we want to keep for further analysis.

```{r}
called_cells <- 
  plot_data %>% 
  filter(edges >= component_filters$minimum_edges,
         rank >= component_filters$minimum_edge_rank)

cat(paste("Out of", nrow(plot_data), "cells,", nrow(called_cells), "were called."))

```

Here we plot the number of called cells per condition and replicate. The target of 500 cells is marked as a dashed line. 

```{r}


called_cells %>% 
  group_by(sample) %>% 
  count() %>% 
  left_join(meta_data,
            by = c("sample")) %>% 
  ggplot(aes(sample, n)) +
  geom_hline(yintercept = 500,
             linetype = "dashed") +
  geom_col(position = position_dodge()) +
  geom_text(aes(label = n),
            vjust = -0.5) +
  scale_y_continuous(expand = expansion(c(0, 0.1))) +
  theme_pg() +
  theme(panel.border = element_blank()) +
  labs(title = "Number of called cells")
ggsave("results/doublet/nbr called cells.png",
       width = 4, height = 3)
ggsave("results/doublet/nbr called cells.pdf",
       width = 4, height = 3)


```

## Inspect component metrics

### Metrics of interest

```{r}

metrics_data %>% 
  inner_join(called_cells %>% 
               select(sample, component),
             by = c("sample", "component")) %>% 
  select(1, 2, all_of(metrics_of_interest)) %>% 
  gather(metric, value, -1, -2) %>% 
  left_join(meta_data, 
            by = "sample") %>% 
  ggplot(aes(sample, value)) +
  geom_violin(draw_quantiles = 0.5, 
              fill = "gray") + 
  facet_grid(metric ~ ., scales = "free") +
  scale_y_log10() +
  theme_pg()
ggsave("results/doublet/metrics of interest violin.png",
       width = 10, height = 7)
ggsave("results/doublet/metrics of interest violin.pdf",
       width = 10, height = 7)



```

### Pixel content vs Marker specificity

Rarily, antibodies form aggregates, which manifest themselves as outliers in Molecular Pixelation data. These usually have either high complexity, consisting of many random antibodies, or low complexity, mainly constituting a single antibody. We detect these by using a metric Tau, which ranges from 0, indicating equal distribution of counts across all antibodies, to 1, indicating all counts distributed to a single antibody. Additionally, aggregates often have dense pixels with a lot of antibodies detected per each pixel, which can be measured using the umi_per_upia metric, which is stored in the component meta data.

Here we have plotted umi_per_upia against Tau, and colored each component by Pixelator's classification of Tau (low, normal, or high). It looks like Pixelator has accurately picked out a few outliers that might be antibody aggregates or components that has low specificity, binding many more different types of antibodies than we would expect from a normal cell. We will remove these from the analysis as well.  

```{r}
metrics_data %>% 
  inner_join(called_cells %>% 
               select(sample, component),
             by = c("sample", "component")) %>% 
  left_join(meta_data,
            by = c("sample")) %>% 
  ggplot(aes(tau, umi_per_upia, color = tau_type)) +
  geom_point() +
  theme_pg() +
  facet_grid(~ sample) +
  scale_y_log10() +
  scale_color_manual(values = c("high" = "orangered2", "low" = "skyblue3", "normal" = "gray")) +
  labs(x = "Marker specificity (Tau)",
       y = "Pixel content (UMI/UPIA)")
ggsave("results/doublet/tau vs pixel content.png",
       width = 12, height = 7)
ggsave("results/doublet/tau vs pixel content.pdf",
       width = 12, height = 7)


```

Here we save a data frame with the cells that are deemed normal. 

```{r}

cleaned_cells <-
  called_cells %>% 
  filter(tau_type == "normal")

cat(paste("Out of", nrow(called_cells), "cells,", nrow(cleaned_cells), "were kept"))
```

### Metrics for called cells

```{r}

plot_data <- 
  metrics_data %>% 
  inner_join(called_cells %>% 
               select(sample, component),
             by = c("sample", "component")) %>% 
  select(1, 2, all_of(c("edges", "umi_per_upia", "reads", "upia", "upib"))) %>% 
  gather(metric, value, -1, -2) %>% 
  mutate(metric = factor(metric, c("reads", "edges", "upia", "upib", "umi_per_upia"))) %>% 
  left_join(meta_data, 
            by = "sample") 
plot_meta <-
  plot_data %>% 
  group_by(metric) %>% 
  summarise(average = median((value)))



```




## Clean data

### Filter data

### Select features

Some markers are unused barcodes (named e.g. BC11 in the data). Let's select only markers we are using in the assay.

```{r}

marker_types <-
  pg_data$S3@assays$RNA %>% 
  rownames() %>% 
  enframe("i", "marker") %>% 
  mutate(marker_type = case_when(str_detect(marker, "^BC\\d") ~ "Empty BC",
                                 str_detect(marker, "^mIgG") ~ "Isotype ctrl",
                                 T ~ "Normal")) 

selected_features <-
  marker_types %>% 
  filter(marker_type != "Empty BC") %>% 
  pull(marker) 

selected_features %>% 
  sort() %>% 
  paste(collapse = ", ") %>% 
  cat()
```


### Remove cells and empty barcodes

Here we filter the data to only keep the cells we have selected, and the markers that we selected in the previous step. 

```{r}

keep_cells <- 
  cleaned_cells %>% 
  mutate(cell_id = paste(sample, component, sep = "_"))

# Merge Seurat objects 
pg_data_comb <- 
  merge(pg_data[[1]],
        y = pg_data[-1],
        add.cell.ids = names(pg_data)) 


# Keep only cells and features we have selected previously
pg_data_comb[["cell_id"]] <- colnames(pg_data_comb)

pg_data_comb <- 
  pg_data_comb %>% 
  subset(subset = cell_id %in% keep_cells$cell_id) %>% 
  subset(features = selected_features)

# Add some meta data directly to the Seurat object. We will need this later.
# Sample ID (e.g. S3)
pg_data_comb[["sample"]] <- str_remove(colnames(pg_data_comb), "_RCVCMP.*")



```

### Isotype abundance

```{r}
plot_data <- 
  pg_data_comb@assays$RNA@counts %>% 
  sweep(2, apply(., 2, sum), "/") %>% 
  as_tibble(rownames = "marker") %>% 
  gather(sample_component, rel, -1) %>% 
  filter(str_detect(marker, "^mIg") | marker == "ACTB") 

plot_meta <- 
  plot_data %>% 
  group_by(marker) %>% 
  summarise(median = median(100*rel))

plot_data %>% 
  ggplot(aes(marker, 100 * rel)) +
  geom_violin(draw_quantiles = 0.5) +
  geom_text(data = plot_meta, 
            aes(y = median, label = paste(round(median, 2), "%")),
            nudge_x = 0.3,
            size = 2,
            hjust = 0) +
  theme_pg() +
  scale_y_continuous(limits = c(0, 3)) +
  labs(x = "Isotype marker",
       y = "% counts")
ggsave("results/doublet/Isotype abundance.png",
       width = 4, height = 4)
ggsave("results/doublet/Isotype abundance.pdf",
       width = 4, height = 4)

```

# Analysis (all cells)

## Select features

```{r}
selected_markers <- 
  pg_data_comb@assays$RNA@counts %>% 
  log1p() %>% 
  apply(MARGIN = 1, mean) %>% 
  exp() %>% 
  `-`(1) %>% 
  sort() %>% 
  enframe() %>% 
  mutate(selected = !(str_detect(name, "^mIg") | name == "TCRb"))

```


## Data processing



### Estimate doublet rate

```{r}
temp_data <- 
  pg_data_comb %>% 
  # CLR transform data: 
  NormalizeData(normalization.method = "CLR", margin = 2)# %>%

plot_data <- 
  left_join(temp_data@assays$RNA@counts %>% 
              log1p() %>% 
              as_tibble(rownames = "marker") %>% 
              gather(sample_component, logcount, -1),
            temp_data@assays$RNA@data %>% 
              as_tibble(rownames = "marker") %>% 
              gather(sample_component, normcount, -1))

marker_combos <- 
  c("CD3E" = "T cell",
    "CD2" = "T cell",
    
    "CD40" = "B cell",
    "CD19" = "B cell",
    "CD20" = "B cell") %>% 
  enframe("marker", "cell_type") %>% 
  expand_grid(., ., 
              .name_repair = function(nams){ 
                enframe(nams) %>% 
                  group_by(value) %>% 
                  mutate(value = paste0(value, row_number())) %>% 
                  pull(value)
              }) %>% 
  filter(cell_type1 < cell_type2)


marker_combo_data <- 
  marker_combos %>% 
  left_join(plot_data,
            by = c("marker1" = "marker")) %>% 
  left_join(plot_data,
            by = c("marker2" = "marker",
                   "sample_component"),
            suffix = c("1", "2")) 

marker_combo_data %>% 
  ggplot(aes(normcount1, normcount2)) +
  geom_point(size = 0.1) +
  facet_grid(marker2 ~ marker1, scales = "free") +
  theme_pg() +
  labs(x = "CLR count",
       y = "CLR count")
ggsave("results/doublet/Doublet scatters.png",
       width = 5, height = 4)
ggsave("results/doublet/Doublet scatters.pdf",
       width = 5, height = 4)

marker_combo_data %>% 
  write_csv("results/doublet/Extended data figure 2A source.csv")

```


### Process data

```{r}

pg_data_comb_processed <-
  pg_data_comb %>% 
  
  # log transform data: 
  NormalizeData(normalization.method = "CLR",
                margin = 2) %>%
  
  
  subset(features = selected_markers$name[which(selected_markers$selected)]) %>% 
  
  # AddMetaData(metadata = log10(.@meta.data$edges), col.name = 'logedges') %>% 
   
  # Find variable features
  FindVariableFeatures(nfeatures = 40) %>%
  
  ScaleData(scale.max = Inf, 
            do.scale = T, 
            do.center = T, 
            # vars.to.regress = c("logedges"),
            verbose = F) %>% 
  # RunPCA(npcs = 30) %>%
  # Remove platelet markers from PCA:
  RunPCA(npcs = 30) %>%
  RunUMAP(umap.method = "uwot",
          min.dist = 0.1,
          spread = 2,
          n.neighbors = 25,
          dims = 1:12) %>% 
   FindNeighbors(dims = 1:12, k.param = 20, prune.SNN = 1/15,
                n.trees = 100) %>% 
  FindClusters(resolution = 0.4, 
               method = "igraph",
               n.start = 40,
               algorithm = 2, 
               random.seed = 42)

VariableFeaturePlot(pg_data_comb_processed, selection.method = "vst") +
  geom_text(data = . %>% 
              as_tibble(rownames = "marker"),
            aes(label = marker, color = colors),
            size = 2,
            vjust = -0.5) +
  theme(plot.background = element_rect(fill = "white", color = NA))
ggsave("results/doublet/variable variance plot.png",
       width = 7, height = 4)
ggsave("results/doublet/variable variance plot.pdf",
       width = 7, height = 4)


DimPlot(pg_data_comb_processed)

# Get umap coords
umap_data <- 
  pg_data_comb_processed@reductions$umap@cell.embeddings %>% 
  as_tibble(rownames = "sample_component") %>% 
  separate(sample_component, into = c("sample", "component"), remove = F) %>% 
  left_join(meta_data) %>% 
  left_join(metrics_data)


umap_data %>% 
  ggplot(aes(UMAP_1, UMAP_2, color = sample)) +
  geom_point(size = 1) + 
  coord_fixed() +
  theme_umap()



umap_data %>% 
  ggplot(aes(UMAP_1, UMAP_2, color = sample)) +
  geom_point(data = . %>% 
               select(-portion_daudi),
             color = "gray", 
             size = 0.5) + 
  geom_point(size = 1) + 
  coord_fixed() +
  facet_grid( ~ portion_daudi) +
  theme_umap()


# Get pca coords
pca_data <- 
  pg_data_comb_processed@reductions$pca@cell.embeddings %>% 
  as_tibble(rownames = "sample_component") %>% 
  separate(sample_component, into = c("sample", "component"), remove = F) %>% 
  left_join(meta_data) %>% 
  left_join(metrics_data)


pca_data %>% 
  ggplot(aes(PC_1, PC_2, color = sample)) +
  geom_point(size = 1) + 
  coord_fixed() +
  theme_umap()



pca_data %>% 
  ggplot(aes(PC_1, PC_2, color = sample)) +
  geom_point(data = . %>% 
               select(-portion_daudi),
             color = "gray", 
             size = 0.5) + 
  geom_point(size = 1) + 
  coord_fixed() +
  facet_grid( ~ portion_daudi) +
  theme_umap()


# Control
FeaturePlot(pg_data_comb_processed, 
            features = c("ACTB",
                         "HLA-ABC",
                         "B2M", 
                         "edges",
                         "umi_per_upia",
                         "tau",
                         "antibodies",
                         "reads"), 
            coord.fixed = T,
            reduction = "pca", 
            dims = c(1,2))

# T/Bcells
FeaturePlot(pg_data_comb_processed, 
            features = c("CD2", 
                         "CD3E",
                         "CD19",
                         "CD20"), 
            coord.fixed = T,
            reduction = "pca",  
            dims = c(1,2))

# T cells
FeaturePlot(pg_data_comb_processed, 
            features = c("CD2", 
                         "CD3E",
                         "CD4",
                         "CD8",
                         "CD16",
                         "CD161"), 
            coord.fixed = T,
            reduction = "pca", 
            dims = c(1,2))



# B cells
FeaturePlot(pg_data_comb_processed, 
            features = c("CD20",
                         "CD19",
                         "CD40"), 
            coord.fixed = T,
            reduction = "pca", 
            dims = c(1,2))


# Combined
FeaturePlot(pg_data_comb_processed, 
            features = c("CD3E",
                         "CD20"),blend = T, 
            coord.fixed = T,
            reduction = "pca", 
            dims = c(1,2))


plot_data <- 
  pca_data %>% 
  left_join(pg_data_comb_processed@assays$RNA@data %>% 
              as_tibble(rownames = "marker") %>% 
              gather(sample_component, clr, -1)) %>% 
  filter(marker %in% c("CD2", 
                       "CD3E",
                       "CD19",
                       "CD20")) %>% 
  group_by(marker) %>% 
  mutate(clr_rel = clr / max(clr)) 

plot_data %>% 
  
  ggplot(aes(PC_1, PC_2, color = clr_rel)) +
  geom_point(size = 1) + 
  facet_wrap(~marker) +
  scale_color_viridis(name = "Relative abundance") +
  coord_fixed() +
  theme_umap()
ggsave("results/doublet/UMAP some markers clr.png",
       width = 6, height = 4)

ggsave("results/doublet/UMAP some markers clr.pdf",
       width = 6, height = 4)

plot_data %>% 
  write_csv("results/doublet/Extended data figure 2B source.csv")


```


# Simulate Doublets 

```{r}

set.seed(42)
random_doublets <- 
  (1:ncol(pg_data_comb_processed@assays$RNA@counts)) %>% 
  expand_grid(i1 = .,
              i2 = .) %>% 
  slice(sample(1:nrow(.), 300))

simulated_doublets <- 
  sapply(1:nrow(random_doublets),
         function(i) {
           pg_data_comb_processed@assays$RNA@counts[,random_doublets$i1[i]] +
             pg_data_comb_processed@assays$RNA@counts[,random_doublets$i2[i]]
           
         }) %>% 
  as_tibble(rownames = "marker")

sim_pca <- 
  left_join(simulated_doublets,
            pg_data_comb_processed@assays$RNA@counts%>% 
              as_tibble(rownames = "marker")) %>% 
  column_to_rownames("marker") %>% 
  compositions::clr() %>% 
  t() %>% 
  scale() %>% 
  pcaMethods::pca()

plot_data <- 
  sim_pca@scores %>% 
  as_tibble(rownames = "id") %>% 
  mutate(is_simulated = str_detect(id, "^V")) 

plot_data2 <- 
  random_doublets %>% 
  mutate(cell1 = colnames(pg_data_comb_processed@assays$RNA@counts)[i1],
         cell2 = colnames(pg_data_comb_processed@assays$RNA@counts)[i2],
         doublet = paste0("V", row_number())) %>% 
  gather(cell_i, id, matches("cell")) %>% 
  left_join(plot_data,
            by = c("id")) %>% 
  left_join(plot_data,
            by = c("doublet" = "id"),
            suffix = c("_original", "_doublet")) 
  

plot_data %>% 
  ggplot(aes(PC1, PC2, color = is_simulated)) +
  geom_segment(data = plot_data2,
               aes(x = PC1_original, xend = PC1_doublet,
                   y = PC2_original, yend = PC2_doublet),
               inherit.aes = F,
               alpha = 0.3) +
  geom_point() +
  theme_umap()
```


# Abundance ratio
```{r}

plot_data <- 
  GetAssayData(pg_data_comb_processed, slot = "counts") %>% 
  as_tibble(rownames = "marker") %>% 
  gather(sample_component, count, -1) %>% 
  mutate(sample = str_remove(sample_component, "_.*")) %>% 
  left_join(meta_data) %>% 
  left_join(pg_data_comb_processed[[]] %>% 
              as_tibble(rownames = "sample_component") %>% 
              select(sample_component, seurat_clusters))  
  

plot_data %>% 
  group_by(seurat_clusters, marker) %>% 
  summarise(count = median(count)) %>% 
  spread(seurat_clusters, count) %>% 
  ggplot(aes(`0` + 1, `1` + 1, label = marker)) +
  geom_abline() +
  geom_point() +
  geom_text() +
  theme_bw()

plot_data2 <- 
  plot_data %>% 
  group_by(seurat_clusters, marker) %>% 
  summarise(count = median(count)) %>% 
  spread(seurat_clusters, count) %>% 
  mutate(ratio = `0` / `1`,
         ratio2 = `1` / `0`) %>% 
  arrange(ratio) %>% 
  mutate(marker = factor(marker, marker)) 

plot_data2 %>% 
  ggplot(aes(ratio, marker, label = round(ratio, 1),
             fill = ratio >= 1)) +
  geom_col() +
  geom_text(data = . %>% 
              filter(ratio >= 1),
            hjust = 0,
            size = 3) +
  geom_text(data = . %>% 
              filter(ratio < 1),
            aes(label = round(ratio2, 1)),
            hjust = 1,
            size = 3) +
  scale_x_log10(expand = expansion(0.1)) +
  theme_bw() +
  theme(panel.grid = element_blank())
ggsave("results/doublet/jurkat daudi dynamic range.png",
       width = 6, height = 9)

ggsave("results/doublet/jurkat daudi dynamic range.pdf",
       width = 6, height = 9)

plot_data2 %>% 
  write_csv("results/doublet/Extended data figure 2C source.csv")


```

